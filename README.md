

## Table of Contents (Optional)

> If your `README` has a lot of info, section headers might be nice.
- [installation](#installation)
- [Data collection](#Data_collection)
- [Data Cleaning](#Data_Cleaning)
- [build network](#Network)
- [Hyperparameters](#Hyperparameters)

---


## Installation
### from conda
- `conda install -c anaconda tensorflow-gpu` 
### from pip
- `pip install tensorflow-gpu` 

## Data collection
- <a href="https://www.kaggle.com/thec03u5/seinfeld-chronicles#scripts.csv" target="_blank">Data Set</a> .

---

## Data_Cleaning
- Lookup Table
### To create a word embedding, you first need to transform the words to ids. 
- Dictionary to go from the words to an id, we'll call vocab_to_int
- Dictionary to go from the id to word, we'll call int_to_vocab

### Tokenize Punctuation

- We'll be splitting the script into a word array using spaces as delimiters. However, punctuations like periods and exclamation marks can create multiple ids for the same word. For example, "bye" and "bye!" would generate two different word ids.

- Implement the function token_lookup to return a dict that will be used to tokenize symbols like "!" into "||Exclamation_Mark||". Create a dictionary for the following symbols where the symbol is the key and value is the token:

- Period ( . )
- Comma ( , )
- Quotation Mark ( " )
- Semicolon ( ; )
- Exclamation mark ( ! )
- Question mark ( ? )
- Left Parentheses ( ( )
- Right Parentheses ( ) )
- Dash ( - )
- Return ( \n )


## network

Build the Neural Network

-Implement an RNN using PyTorch's Module class. You may choose to use a GRU or an LSTM. To complete the RNN, you'll have to implement the following functions for the class:

- __init__ - The initialize function.
- init_hidden - The initialization function for an LSTM/GRU hidden state
- Define forward and backpropagation
- If a GPU is available, you should move your data to that GPU device, here.
- Train data

## Hyperparameters
- Set sequence_length to the length of a sequence.
- Set batch_size to the batch size.
- Set num_epochs to the number of epochs to train for.
- Set learning_rate to the learning rate for an Adam optimizer.
- Set vocab_size to the number of uniqe tokens in our vocabulary.
- Set output_size to the desired size of the output.
- Set embedding_dim to the embedding dimension; smaller than the vocab_size.
- Set hidden_dim to the hidden dimension of your RNN.
- Set n_layers to the number of layers/cells in your RNN.
- Set show_every_n_batches to the number of batches at which the neural network should print progress.

---

## At last call the generate function to generate new scripts generated by out model
